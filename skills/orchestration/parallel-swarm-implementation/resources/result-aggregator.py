#!/usr/bin/env python3
"""
Result Aggregator - Collect and Synthesize Multi-Agent Execution Results
Part of Loop 2: Parallel Swarm Implementation (Enhanced Tier)

This script aggregates results from parallel agent execution, performs
consensus validation, and generates delivery packages for Loop 3.
"""

import json
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime
from collections import defaultdict


@dataclass
class TaskResult:
    """Individual task execution result"""
    taskId: str
    agent: str
    skill: Optional[str]
    success: bool
    executionTime: int  # milliseconds
    filesCreated: List[str]
    error: Optional[str]
    timestamp: str


@dataclass
class TheaterDetection:
    """Theater detection consensus result"""
    taskId: str
    detectors: List[str]  # Agents that detected
    confidence: float  # 0.0-1.0
    theaterType: str  # completion, test, docs, etc.
    description: str


@dataclass
class QualityMetrics:
    """Aggregated quality metrics"""
    integrationTestPassRate: float
    functionalityAuditPass: bool
    theaterAuditPass: bool
    codeReviewScore: int  # 0-100
    testCoverage: float
    theaterDetected: int


@dataclass
class DeliveryPackage:
    """Loop 2 delivery package for Loop 3"""
    metadata: Dict[str, Any]
    agentSkillMatrix: Dict[str, Any]
    implementation: Dict[str, Any]
    qualityMetrics: QualityMetrics
    integrationPoints: Dict[str, Any]


class ResultAggregator:
    """Aggregate and validate multi-agent execution results"""

    def __init__(self, matrix_path: str, execution_log_path: str):
        """
        Initialize aggregator with execution data.

        Args:
            matrix_path: Path to agent-skill-assignments.json
            execution_log_path: Path to execution-summary.json
        """
        self.matrix_path = Path(matrix_path)
        self.execution_log_path = Path(execution_log_path)
        self.matrix: Dict[str, Any] = {}
        self.execution_log: Dict[str, Any] = {}
        self.task_results: List[TaskResult] = []
        self.theater_detections: List[TheaterDetection] = []

    def load_data(self) -> None:
        """Load execution data from files"""
        # Load matrix
        if not self.matrix_path.exists():
            raise FileNotFoundError(f"Matrix not found: {self.matrix_path}")

        with open(self.matrix_path, 'r') as f:
            self.matrix = json.load(f)

        print(f"‚úÖ Loaded matrix: {self.matrix['project']}")

        # Load execution log
        if not self.execution_log_path.exists():
            raise FileNotFoundError(f"Execution log not found: {self.execution_log_path}")

        with open(self.execution_log_path, 'r') as f:
            self.execution_log = json.load(f)

        print(f"‚úÖ Loaded execution log: {self.execution_log['execution']['totalExecuted']} tasks")

    def aggregate_task_results(self) -> None:
        """Aggregate individual task results"""
        print("\nüìä Aggregating task results...")

        # In production, would load from actual execution logs
        # For this example, we'll use the execution summary

        # Map task results
        for task in self.matrix['tasks']:
            # Find corresponding execution result
            # (Simplified - would have actual execution data)
            result = TaskResult(
                taskId=task['taskId'],
                agent=task['assignedAgent'],
                skill=task['useSkill'],
                success=True,  # Would come from actual execution
                executionTime=2500,  # Would come from actual execution
                filesCreated=[],  # Would scan filesystem
                error=None,
                timestamp=datetime.now().isoformat()
            )

            self.task_results.append(result)

        successful = sum(1 for r in self.task_results if r.success)
        print(f"   Tasks: {successful}/{len(self.task_results)} successful")

    def perform_theater_consensus(self) -> None:
        """
        Perform multi-agent theater detection consensus.

        Implements Byzantine consensus with 4/5 agreement threshold.
        """
        print("\nüé≠ Performing theater detection consensus...")

        # Simulated theater detection (in production, would query actual detectors)
        theater_reports = [
            # Format: (taskId, detector, confidence, type, description)
        ]

        # Group detections by task
        detections_by_task = defaultdict(list)
        for taskId, detector, confidence, theater_type, description in theater_reports:
            detections_by_task[taskId].append({
                'detector': detector,
                'confidence': confidence,
                'type': theater_type,
                'description': description
            })

        # Apply Byzantine consensus (require 4/5 agreement)
        REQUIRED_AGREEMENT = 0.8  # 80% of detectors
        TOTAL_DETECTORS = 5  # Code, Tests, Docs, Sandbox, Integration

        for taskId, detections in detections_by_task.items():
            if len(detections) >= (TOTAL_DETECTORS * REQUIRED_AGREEMENT):
                # Confirmed theater - high confidence
                avg_confidence = sum(d['confidence'] for d in detections) / len(detections)

                theater = TheaterDetection(
                    taskId=taskId,
                    detectors=[d['detector'] for d in detections],
                    confidence=avg_confidence,
                    theaterType=detections[0]['type'],
                    description=detections[0]['description']
                )

                self.theater_detections.append(theater)

        if self.theater_detections:
            print(f"   ‚ùå Theater detected: {len(self.theater_detections)} instances")
            for detection in self.theater_detections:
                print(f"      {detection.taskId}: {detection.theaterType} ({detection.confidence:.0%} confidence)")
        else:
            print("   ‚úÖ No theater detected - 100% genuine implementation")

    def calculate_quality_metrics(self) -> QualityMetrics:
        """
        Calculate aggregated quality metrics.

        Returns:
            QualityMetrics object with all quality indicators
        """
        print("\nüìà Calculating quality metrics...")

        # Integration test pass rate (would scan test results)
        integration_pass_rate = 100.0  # 100% in simulation

        # Functionality audit pass (would check sandbox validation)
        functionality_pass = len(self.theater_detections) == 0

        # Theater audit pass (zero tolerance)
        theater_pass = len(self.theater_detections) == 0

        # Code review score (would aggregate from reviewers)
        code_review_score = 85  # 0-100 scale

        # Test coverage (would parse coverage reports)
        test_coverage = 92.5  # percentage

        metrics = QualityMetrics(
            integrationTestPassRate=integration_pass_rate,
            functionalityAuditPass=functionality_pass,
            theaterAuditPass=theater_pass,
            codeReviewScore=code_review_score,
            testCoverage=test_coverage,
            theaterDetected=len(self.theater_detections)
        )

        print(f"   Integration Tests: {metrics.integrationTestPassRate}%")
        print(f"   Functionality Audit: {'PASS' if metrics.functionalityAuditPass else 'FAIL'}")
        print(f"   Theater Audit: {'PASS' if metrics.theaterAuditPass else 'FAIL'}")
        print(f"   Code Review Score: {metrics.codeReviewScore}/100")
        print(f"   Test Coverage: {metrics.testCoverage}%")

        return metrics

    def generate_delivery_package(self, output_path: str) -> None:
        """
        Generate Loop 2 delivery package for Loop 3.

        Args:
            output_path: Path to save delivery package
        """
        print("\nüì¶ Generating delivery package for Loop 3...")

        # Calculate quality metrics
        quality_metrics = self.calculate_quality_metrics()

        # Collect files created (would scan filesystem in production)
        files_created = [
            "src/auth/jwt.ts",
            "src/auth/middleware.ts",
            "tests/auth/jwt.test.ts",
            "docs/API.md"
        ]

        # Build delivery package
        delivery = DeliveryPackage(
            metadata={
                'loop': 2,
                'phase': 'parallel-swarm-implementation',
                'timestamp': datetime.now().isoformat(),
                'nextLoop': 'cicd-intelligent-recovery',
                'project': self.matrix['project']
            },
            agentSkillMatrix=self.matrix,
            implementation={
                'filesCreated': files_created,
                'testsCoverage': quality_metrics.testCoverage,
                'theaterDetected': quality_metrics.theaterDetected,
                'sandboxValidation': quality_metrics.functionalityAuditPass
            },
            qualityMetrics=quality_metrics,
            integrationPoints={
                'receivedFrom': 'research-driven-planning',
                'feedsTo': 'cicd-intelligent-recovery',
                'memoryNamespaces': {
                    'input': 'integration/loop1-to-loop2',
                    'coordination': 'swarm/coordination',
                    'output': 'integration/loop2-to-loop3'
                }
            }
        )

        # Convert to dict for JSON serialization
        delivery_dict = {
            'metadata': delivery.metadata,
            'agent_skill_matrix': delivery.agentSkillMatrix,
            'implementation': delivery.implementation,
            'quality_metrics': asdict(delivery.qualityMetrics),
            'integrationPoints': delivery.integrationPoints
        }

        # Save to file
        output = Path(output_path)
        output.parent.mkdir(parents=True, exist_ok=True)

        with open(output, 'w') as f:
            json.dump(delivery_dict, f, indent=2)

        print(f"‚úÖ Saved delivery package: {output}")

        # Store in memory (simulated)
        print("\nüíæ Storing in memory namespace: integration/loop2-to-loop3")
        # In production:
        # npx claude-flow@alpha memory store "loop2_complete" "$(cat output)" --namespace "integration/loop2-to-loop3"

        # Ready for Loop 3
        print("\n‚úÖ Loop 2 Complete - Ready for Loop 3 (CI/CD Intelligent Recovery)")

    def generate_summary_report(self) -> None:
        """Generate human-readable summary report"""
        print("\n" + "=" * 70)
        print("LOOP 2 EXECUTION SUMMARY")
        print("=" * 70)

        print(f"\nProject: {self.matrix['project']}")
        print(f"Timestamp: {datetime.now().isoformat()}")

        print("\nüìã Agent+Skill Matrix:")
        print(f"   Total Tasks: {self.matrix['statistics']['totalTasks']}")
        print(f"   Skill-Based: {self.matrix['statistics']['skillBasedAgents']}")
        print(f"   Custom Instructions: {self.matrix['statistics']['customInstructionAgents']}")
        print(f"   Unique Agents: {self.matrix['statistics']['uniqueAgents']}")
        print(f"   Parallelism: {self.matrix['statistics']['estimatedParallelism']}")

        print("\nüöÄ Execution Results:")
        successful = sum(1 for r in self.task_results if r.success)
        print(f"   Total Executed: {len(self.task_results)}")
        print(f"   Successful: {successful}")
        print(f"   Failed: {len(self.task_results) - successful}")

        print("\nüé≠ Theater Detection:")
        if self.theater_detections:
            print(f"   ‚ùå Theater Found: {len(self.theater_detections)} instances")
            print("   BLOCKING MERGE - Review theater detections")
        else:
            print("   ‚úÖ Zero Theater - 100% Genuine Implementation")

        print("\nüìä Quality Gates:")
        quality = self.calculate_quality_metrics()
        print(f"   Integration Tests: {quality.integrationTestPassRate}% pass rate")
        print(f"   Test Coverage: {quality.testCoverage}%")
        print(f"   Code Review Score: {quality.codeReviewScore}/100")
        print(f"   Functionality Audit: {'PASS' if quality.functionalityAuditPass else 'FAIL'}")
        print(f"   Theater Audit: {'PASS' if quality.theaterAuditPass else 'FAIL'}")

        print("\nüîó Integration:")
        print("   Received From: Loop 1 (research-driven-planning)")
        print("   Feeds To: Loop 3 (cicd-intelligent-recovery)")

        print("\n" + "=" * 70)


def main():
    """Main entry point"""
    if len(sys.argv) < 3:
        print("Usage: python result-aggregator.py <matrix.json> <execution-summary.json> [output.json]")
        sys.exit(1)

    matrix_path = sys.argv[1]
    execution_log = sys.argv[2]
    output_path = sys.argv[3] if len(sys.argv) > 3 else ".claude/.artifacts/loop2-delivery-package.json"

    print("=== Result Aggregator - Loop 2 Completion ===\n")

    aggregator = ResultAggregator(matrix_path, execution_log)

    # Load data
    aggregator.load_data()

    # Aggregate results
    aggregator.aggregate_task_results()

    # Theater detection
    aggregator.perform_theater_consensus()

    # Generate delivery package
    aggregator.generate_delivery_package(output_path)

    # Summary report
    aggregator.generate_summary_report()


if __name__ == "__main__":
    main()
